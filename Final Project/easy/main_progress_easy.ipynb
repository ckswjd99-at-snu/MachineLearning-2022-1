{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setting\n",
    "Google drive mount (for Colab users) and package importing.\n",
    "You can optionally install and import torchensemble package for ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random  \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Sample Visualization\n",
    "You can see actual sample images and sorted class indices. Additional matplotlib package is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for reference: see actual samples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alphabet = {\n",
    "        'A(a)' : '0', 'B(b)' : '1', 'C(c)' : '2', 'D(d)' : '3', 'E(e)' : '4', 'F(f)' : '5', \n",
    "        'G(g)' : '6', 'H(h)' : '7', 'I(i)' : '8', 'J(j)' : '9', 'K(k)' : '10','L(l)' : '11', \n",
    "        'M(m)' : '12', 'N(n)' : '13', 'O(o)' : '14', 'P(p)' : '15', 'Q(q)' : '16', 'R(r)' : '17', \n",
    "        'S(s)' : '18', 'T(t)' : '19', 'U(u)' : '20', 'V(v)' : '21', 'W(w)' : '22', 'X(x)' : '23', \n",
    "        'Y(y)' : '24', 'Z(z)' : '25'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Just for reference: see actual samples\n",
    "\n",
    "load_sample = np.load('../../easy archive/emnist_progress_easy_data/sample_data.npy', allow_pickle=True).item()\n",
    "# load_sample = np.load('/content/drive/MyDrive/final_proj_colab/emnist_progress_easy_data/sample_data.npy', allow_pickle=True).item()\n",
    "sample_data, sample_label = load_sample['train_data'], load_sample['train_label']\n",
    "print(len(sample_data))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(len(sample_data),len(sample_data)))\n",
    "for i in range(len(sample_data)):\n",
    "    plt.subplot(1, len(sample_data), i+1)\n",
    "    ax = plt.gca()\n",
    "    ax.axes.xaxis.set_ticklabels([])\n",
    "    ax.axes.yaxis.set_ticklabels([])\n",
    "    plt.imshow(sample_data[i], cmap='gray')\n",
    "    \n",
    "plt.show()\n",
    "print(\"progress label: \", end=' ')\n",
    "label_str = '('\n",
    "\n",
    "for i in range(len(sample_label)):\n",
    "    print(int(sample_label[i]), end=' ')\n",
    "    label_str += \" \" + list(alphabet.keys())[int(sample_label[i])]\n",
    "label_str += \" )\"\n",
    "print()\n",
    "print(label_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Use 0th GPU for training\n",
    "torch.cuda.set_device(0)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:16:8\n"
     ]
    }
   ],
   "source": [
    "# fix random seed to increase reproducibility\n",
    "# NOTE: Do not modify here!\n",
    "\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "%env CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "\n",
    "def seed_worker(worker_seed):\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "# you can modify this\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: you can modify mean and std for normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 load from 0 to 5000\n",
      "1 load from 5000 to 10000\n",
      "2 load from 10000 to 15000\n",
      "3 load from 15000 to 20000\n",
      "4 load from 20000 to 25000\n",
      "5 load from 25000 to 30000\n",
      "6 load from 30000 to 35000\n",
      "7 load from 35000 to 40000\n",
      "8 load from 40000 to 45000\n",
      "9 load from 45000 to 50000\n",
      "0 load from 0 to 5000\n",
      "1 load from 5000 to 10000\n"
     ]
    }
   ],
   "source": [
    "# NOTE: modify path for your setting\n",
    "\n",
    "from data_utils import Mydataset, collate_fn\n",
    "\n",
    "train_path = '../../easy archive/emnist_progress_easy_data/train'\n",
    "valid_path = '../../easy archive/emnist_progress_easy_data/valid'\n",
    "# train_path = '/content/drive/MyDrive/final_proj_colab/emnist_progress_easy_data/train'\n",
    "# valid_path = '/content/drive/MyDrive/final_proj_colab/emnist_progress_easy_data/valid'\n",
    "\n",
    "train_ds = Mydataset(train_path, transform=transform, train=True)\n",
    "valid_ds = Mydataset(valid_path, transform=transform, train=False)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "valid_dl= DataLoader(valid_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, model_optim, loss_func, max_epoch, train_dl, valid_dl, \n",
    "          load_path=None, save_path='./model.pt'):\n",
    "    ##############################################################################\n",
    "    #                          IMPLEMENT YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    # Load your states\n",
    "    loaded_epoch = 0\n",
    "    loaded_best_acc = -1\n",
    "    if load_path is not None:\n",
    "        state = torch.load(load_path)\n",
    "        model.load_state_dict(state[\"model\"])\n",
    "        model_optim.load_state_dict(state[\"optimizer\"])\n",
    "        loaded_epoch = state[\"epoch\"]\n",
    "        loaded_best_acc = state[\"best_acc\"]\n",
    "        # ...\n",
    "    start_time = time.time()\n",
    "        \n",
    "    ##############################################################################\n",
    "    #                          END OF YOUR CODE                                  #\n",
    "    ##############################################################################\n",
    "    \n",
    "    best_valid_accuracy = 0 if loaded_best_acc == -1 else loaded_best_acc\n",
    "\n",
    "    for epoch in np.array(list(range(max_epoch - loaded_epoch))) + loaded_epoch:\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        model.train()\n",
    "        for step, sample in enumerate(train_dl):\n",
    "            img, label = sample\n",
    "            batch_size = len(img)\n",
    "            outputs = model(img)    # List[ Tensor(seq_len, 26) * batch_size ]\n",
    "            \n",
    "            ##############################################################################\n",
    "            #                          IMPLEMENT YOUR CODE                               #\n",
    "            ##############################################################################\n",
    "            # Problem 4: implement optimization part   \n",
    "\n",
    "            # outputs: List[ Tensor(seq_len, 26) * batch_size ]\n",
    "            # label: List[ Tensor(seq_len+1) * batch_size ]\n",
    "            answer_label = [l[1:] for l in label]   # List[ Tensor(seq_len) * batch_size ]\n",
    "            # Tensor(sum(seq_len))\n",
    "            answer_oh_label = [F.one_hot(al.type(torch.int64), num_classes=26).type(torch.float).to('cuda:0') for al in answer_label]\n",
    "            # List[ Tensor(seq_len, 26) * batch_size ]\n",
    "\n",
    "            output_lasts = torch.cat([o[-1] for o in outputs]).reshape(batch_size, 26)\n",
    "            answer_lasts = torch.cat([l[-1] for l in answer_oh_label]).reshape(batch_size, 26)\n",
    "\n",
    "            output_rears = [o[1:] for o in outputs]             # List[ Tensor(1:seq_len, 26) * batch_size ]\n",
    "            answer_rears = [l[1:] for l in answer_oh_label]     # List[ Tensor(1:seq_len, 26) * batch_size ]\n",
    "\n",
    "            # Loss of only-last\n",
    "            loss = loss_func(output_lasts, answer_lasts)\n",
    "\n",
    "            # Loss of except-first\n",
    "            # loss = 0\n",
    "            # for out_rear, ans_rear in zip(output_rears, answer_rears):\n",
    "            #     # out_rear: Tensor(1:seq_len, 26)\n",
    "            #     # ans_rear: Tensor(1:seq_len, 26)\n",
    "            #     loss += loss_func(out_rear, ans_rear)\n",
    "            # loss /= batch_size\n",
    "\n",
    "\n",
    "            model_optim.zero_grad()\n",
    "            loss.backward()\n",
    "            model_optim.step()\n",
    "            \n",
    "            \n",
    "            ##############################################################################\n",
    "            #                          END OF YOUR CODE                                  #\n",
    "            ##############################################################################\n",
    "            \n",
    "            # you can modify below train evaluation code\n",
    "            \n",
    "            n_samples += len(outputs)\n",
    "            for j in range(len(outputs)):\n",
    "                if outputs[j][-1].argmax(-1).item() == label[j][-1]:\n",
    "                    n_correct += 1\n",
    "            \n",
    "            if (step + 1) % print_interval == 0:\n",
    "                print('epoch:', epoch + 1, 'step:', step + 1, 'loss:', loss.item(), 'accuracy:', (n_correct / n_samples))\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print('elapsed time : %d h %d m %d s' % (elapsed_time / 3600, (elapsed_time % 3600) / 60, (elapsed_time % 60)))\n",
    "                print(outputs[0].argmax(-1))\n",
    "                print(answer_label[0])\n",
    "                \n",
    "       \n",
    "\n",
    "        \n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            o_save = a_save = None\n",
    "            for step, sample in enumerate(valid_dl):\n",
    "                img, label = sample            \n",
    "                outputs = model(img)    # List[ Tensor(seq_len, 26) * batch_size ]\n",
    "                output_letter = torch.Tensor([o[-1].argmax(-1) for o in outputs])   # Tensor(batch_size, 1)\n",
    "                answers = torch.Tensor([l[-1] for l in label])\n",
    "\n",
    "                n_samples += len(outputs)\n",
    "                for j in range(len(outputs)):\n",
    "                    if outputs[j][-1].argmax(-1).item() == label[j][-1]:\n",
    "                        n_correct += 1\n",
    "\n",
    "                o_save = outputs[0].argmax(-1)\n",
    "                a_save = label[0][1:]\n",
    "                # break\n",
    "            print(o_save)\n",
    "            print(a_save)\n",
    "            \n",
    "            valid_accuracy = n_correct/n_samples\n",
    "            if valid_accuracy > best_valid_accuracy:\n",
    "                print(\"New best valid accuracy, saving model\")\n",
    "                ##############################################################################\n",
    "                #                          IMPLEMENT YOUR CODE                               #\n",
    "                ##############################################################################\n",
    "                # Save your states (optional)\n",
    "                state = {\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"optimizer\": model_optim.state_dict(),\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"best_acc\": best_valid_accuracy,\n",
    "                    # ...\n",
    "                }\n",
    "                ##############################################################################\n",
    "                #                          END OF YOUR CODE                                  #\n",
    "                ##############################################################################\n",
    "                torch.save(state, save_path)\n",
    "                best_valid_accuracy = valid_accuracy\n",
    "            print('Valid epoch: %d, Valid accuracy: %f, Best valid accuracy: %f' % (epoch + 1, valid_accuracy, best_valid_accuracy))\n",
    "\n",
    "# you can modify evaluation code\n",
    "\n",
    "def eval(valid_dl, load_path):\n",
    "    state = torch.load(load_path)\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    ##############################################################################\n",
    "    #                          IMPLEMENT YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    # Problem 5: implement evaluation part\n",
    "    # you can simply copy or modify above evaluation code in train function\n",
    "\n",
    "    n_samples = 0\n",
    "    n_correct = 0\n",
    "    valid_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for step, sample in enumerate(valid_dl):\n",
    "            img, label = sample            \n",
    "            outputs = model(img)\n",
    "\n",
    "            n_samples += len(outputs)\n",
    "            for j in range(len(outputs)):\n",
    "                if outputs[j][-1].argmax(-1).item() == label[j][-1]:\n",
    "                    n_correct += 1\n",
    "        \n",
    "        valid_accuracy = (n_correct/n_samples)\n",
    "    print(n_samples, n_correct)\n",
    "            \n",
    "    ##############################################################################\n",
    "    #                          END OF YOUR CODE                                  #\n",
    "    ##############################################################################\n",
    "        \n",
    "    \n",
    "    print('Valid accuracy: %.2f' % (valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add or modify your ConvLSTM's hyperparameter (keys and values)\n",
    "kwargs = {\n",
    "    'cnn_input_dim': 1,\n",
    "    'rnn_input_dim': 256,\n",
    "    'rnn_hidden_size': 32,\n",
    "    'rnn_num_layers': 2,\n",
    "    'rnn_dropout': 0.1\n",
    "}\n",
    "\n",
    "NUM_CLASSES = 26\n",
    "SEQUENCE_LENGTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for reload .py file without restart\n",
    "import models_easy\n",
    "importlib.reload(models_easy)\n",
    "\n",
    "from models_easy import ConvLSTM\n",
    "\n",
    "model = ConvLSTM(\n",
    "  cnn_output_size=256,\n",
    "  rnn_num_layers=2\n",
    ").cuda()\n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "model_optim = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: you can modify hyperparameters\n",
    "\n",
    "print_interval = 100\n",
    "max_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_path = None\n",
    "train(model, model_optim, loss_func, max_epoch, train_dl, valid_dl, load_path=load_path, save_path='./model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 9889\n",
      "Valid accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "# load and evaluate model\n",
    "load_path = './0.99.pt'\n",
    "eval(valid_dl, load_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**결과적으로 사용한 모델은 보고서에서 \"Normal Dataset\" 으로 설명한 모델입니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test code for grading by TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you do not need to modify here\n",
    "from data_utils import Mydataset, collate_fn\n",
    "\n",
    "test_path = './data/emnist_progress_easy_data/test'\n",
    "test_ds = Mydataset(test_path, transform=transform, train=False)\n",
    "test_dl= DataLoader(test_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please change the model name to your submission model name\n",
    "load_path = './0.99.pt'\n",
    "eval(test_dl, load_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
